# .github/workflows/process-manual-article.yml
name: Process Single Manual Article
on:
  workflow_dispatch:
    inputs:
      article_url:
        description: 'Article URL to process'
        required: true
        type: string
      submitted_by:
        description: 'Who submitted this article'
        required: false
        default: 'admin'
        type: string
  repository_dispatch:
    types: [process-manual-article]

jobs:
  process-article:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: npm install
      
    - name: Extract article details
      id: extract_article
      run: |
        # Get URL from input or dispatch event
        if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
          ARTICLE_URL="${{ github.event.client_payload.article_url }}"
          SUBMITTED_BY="${{ github.event.client_payload.submitted_by }}"
        else
          ARTICLE_URL="${{ github.event.inputs.article_url }}"
          SUBMITTED_BY="${{ github.event.inputs.submitted_by }}"
        fi
        
        echo "article_url=$ARTICLE_URL" >> $GITHUB_OUTPUT
        echo "submitted_by=$SUBMITTED_BY" >> $GITHUB_OUTPUT
        echo "Processing: $ARTICLE_URL"
        
    - name: Process single article
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ARTICLE_URL: ${{ steps.extract_article.outputs.article_url }}
        SUBMITTED_BY: ${{ steps.extract_article.outputs.submitted_by }}
        ENTRY_ID: ${{ github.event.client_payload.entry_id }} 
      run: |
        cat > process-single-article.js << 'EOF'
        import fs from 'fs/promises';
        import fetch from 'node-fetch';

        console.log('üîÑ PROCESSING SINGLE MANUAL ARTICLE');
        console.log('===================================');
        
        const ARTICLE_URL = process.env.ARTICLE_URL;
        const SUBMITTED_BY = process.env.SUBMITTED_BY || 'admin';
        
        console.log(`üìé URL: ${ARTICLE_URL}`);
        console.log(`üë§ Submitted by: ${SUBMITTED_BY}\n`);

        // Generate simple ID
        function generateId() {
            return Date.now() + '-' + Math.random().toString(36).substr(2, 9);
        }

        // Check if source is verified
        function isVerifiedSource(url) {
            const verifiedDomains = [
                'reuters.com', 'ap.org', 'apnews.com', 'wsj.com', 'nytimes.com',
                'washingtonpost.com', 'usatoday.com', 'bbc.com', 'bbc.co.uk',
                'cnn.com', 'foxnews.com', 'nbcnews.com', 'abcnews.go.com', 
                'cbsnews.com', 'msnbc.com', 'npr.org', 'pbs.org', 'politico.com',
                'thehill.com', 'axios.com', 'bloomberg.com', 'cnbc.com', 'forbes.com',
                'propublica.org', 'courthousenews.com'
            ];
            
            try {
                const domain = new URL(url).hostname.toLowerCase();
                return verifiedDomains.some(verified => domain.includes(verified)) || domain.endsWith('.gov');
            } catch {
                return false;
            }
        }

        // Fetch article content with enhanced anti-bot protection
        async function fetchArticleContent(url) {
            const userAgents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko/20100101 Firefox/120.0'
            ];
            
            console.log(`üìÑ Fetching content from: ${url}`);
            
            for (let attempt = 0; attempt < userAgents.length; attempt++) {
                try {
                    const userAgent = userAgents[attempt];
                    console.log(`üîÑ Attempt ${attempt + 1}/${userAgents.length} with User-Agent: ${userAgent.split(' ')[2]}...`);
                    
                    // FIX: Proper timeout implementation
                    const controller = new AbortController();
                    const timeoutId = setTimeout(() => controller.abort(), 15000);
                    
                    const response = await fetch(url, {
                        headers: {
                            'User-Agent': userAgent,
                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                            'Accept-Language': 'en-US,en;q=0.5',
                            'Accept-Encoding': 'gzip, deflate',
                            'DNT': '1',
                            'Connection': 'keep-alive',
                            'Upgrade-Insecure-Requests': '1',
                            'Sec-Fetch-Dest': 'document',
                            'Sec-Fetch-Mode': 'navigate',
                            'Sec-Fetch-Site': 'none',
                            'Cache-Control': 'max-age=0'
                        },
                        signal: controller.signal
                    });
                    
                    clearTimeout(timeoutId);
                
                    if (response.ok) {
                        const html = await response.text();
                        console.log(`‚úÖ Successfully fetched content (${html.length} bytes)`);
                        return extractArticleData(html, url);
                    } else {
                        console.log(`‚ö†Ô∏è Attempt ${attempt + 1} failed: HTTP ${response.status}`);
                        if (attempt === userAgents.length - 1) {
                            throw new Error(`All fetch attempts failed. Final: HTTP ${response.status}: ${response.statusText}`);
                        }
                        await new Promise(resolve => setTimeout(resolve, 1000));
                    }
                    
                } catch (error) {
                    console.log(`‚ö†Ô∏è Attempt ${attempt + 1} error: ${error.message}`);
                    if (attempt === userAgents.length - 1) {
                        console.log(`üîß All fetch attempts failed, creating manual entry...`);
                        return createManualEntry(url);
                    }
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }
        }
        
        // Extract article data from HTML
        function extractArticleData(html, url) {
            try {
                
                // Extract title
                const titleMatches = [
                    html.match(/<meta[^>]+property="og:title"[^>]+content="([^"]+)"/i),
                    html.match(/<meta[^>]+name="twitter:title"[^>]+content="([^"]+)"/i),
                    html.match(/<title[^>]*>([^<]+)<\/title>/i),
                    html.match(/<h1[^>]*>([^<]+)<\/h1>/i)
                ];
                
                const titleMatch = titleMatches.find(match => match);
                let title = titleMatch ? titleMatch[1].trim() : '';
                
                // Clean up title
                title = title.replace(/&quot;/g, '"')
                           .replace(/&amp;/g, '&')
                           .replace(/&lt;/g, '<')
                           .replace(/&gt;/g, '>')
                           .replace(/\s+/g, ' ')
                           .trim();
                
                // Remove site name from title
                const siteName = new URL(url).hostname.replace('www.', '');
                title = title.replace(new RegExp(`\\s*[-|‚Äì]\\s*${siteName}.*# .github/workflows/process-manual-article.yml
name: Process Single Manual Article
on:
  workflow_dispatch:
    inputs:
      article_url:
        description: 'Article URL to process'
        required: true
        type: string
      submitted_by:
        description: 'Who submitted this article'
        required: false
        default: 'admin'
        type: string
  repository_dispatch:
    types: [process-manual-article]

jobs:
  process-article:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Install dependencies
      run: npm install
      
    - name: Extract article details
      id: extract_article
      run: |
        # Get URL from input or dispatch event
        if [ "${{ github.event_name }}" = "repository_dispatch" ]; then
          ARTICLE_URL="${{ github.event.client_payload.article_url }}"
          SUBMITTED_BY="${{ github.event.client_payload.submitted_by }}"
        else
          ARTICLE_URL="${{ github.event.inputs.article_url }}"
          SUBMITTED_BY="${{ github.event.inputs.submitted_by }}"
        fi
        
        echo "article_url=$ARTICLE_URL" >> $GITHUB_OUTPUT
        echo "submitted_by=$SUBMITTED_BY" >> $GITHUB_OUTPUT
        echo "Processing: $ARTICLE_URL"
        
    - name: Process single article
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ARTICLE_URL: ${{ steps.extract_article.outputs.article_url }}
        SUBMITTED_BY: ${{ steps.extract_article.outputs.submitted_by }}
        ENTRY_ID: ${{ github.event.client_payload.entry_id }} 
      run: |
        cat > process-single-article.js << 'EOF'
        import fs from 'fs/promises';
        import fetch from 'node-fetch';

        console.log('üîÑ PROCESSING SINGLE MANUAL ARTICLE');
        console.log('===================================');
        
        const ARTICLE_URL = process.env.ARTICLE_URL;
        const SUBMITTED_BY = process.env.SUBMITTED_BY || 'admin';
        
        console.log(`üìé URL: ${ARTICLE_URL}`);
        console.log(`üë§ Submitted by: ${SUBMITTED_BY}\n`);

        // Generate simple ID
        function generateId() {
            return Date.now() + '-' + Math.random().toString(36).substr(2, 9);
        }

        // Check if source is verified
        function isVerifiedSource(url) {
            const verifiedDomains = [
                'reuters.com', 'ap.org', 'apnews.com', 'wsj.com', 'nytimes.com',
                'washingtonpost.com', 'usatoday.com', 'bbc.com', 'bbc.co.uk',
                'cnn.com', 'foxnews.com', 'nbcnews.com', 'abcnews.go.com', 
                'cbsnews.com', 'msnbc.com', 'npr.org', 'pbs.org', 'politico.com',
                'thehill.com', 'axios.com', 'bloomberg.com', 'cnbc.com', 'forbes.com',
                'propublica.org', 'courthousenews.com'
            ];
            
            try {
                const domain = new URL(url).hostname.toLowerCase();
                return verifiedDomains.some(verified => domain.includes(verified)) || domain.endsWith('.gov');
            } catch {
                return false;
            }
        }

        // Fetch article content with enhanced anti-bot protection
        async function fetchArticleContent(url) {
            const userAgents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko/20100101 Firefox/120.0'
            ];
            
            console.log(`üìÑ Fetching content from: ${url}`);
            
            for (let attempt = 0; attempt < userAgents.length; attempt++) {
                try {
                    const userAgent = userAgents[attempt];
                    console.log(`üîÑ Attempt ${attempt + 1}/${userAgents.length} with User-Agent: ${userAgent.split(' ')[2]}...`);
                    
                    // FIX: Proper timeout implementation
                    const controller = new AbortController();
                    const timeoutId = setTimeout(() => controller.abort(), 15000);
                    
                    const response = await fetch(url, {
                        headers: {
                            'User-Agent': userAgent,
                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                            'Accept-Language': 'en-US,en;q=0.5',
                            'Accept-Encoding': 'gzip, deflate',
                            'DNT': '1',
                            'Connection': 'keep-alive',
                            'Upgrade-Insecure-Requests': '1',
                            'Sec-Fetch-Dest': 'document',
                            'Sec-Fetch-Mode': 'navigate',
                            'Sec-Fetch-Site': 'none',
                            'Cache-Control': 'max-age=0'
                        },
                        signal: controller.signal
                    });
                    
                    clearTimeout(timeoutId);
                
                    if (response.ok) {
                        const html = await response.text();
                        console.log(`‚úÖ Successfully fetched content (${html.length} bytes)`);
                        return extractArticleData(html, url);
                    } else {
                        console.log(`‚ö†Ô∏è Attempt ${attempt + 1} failed: HTTP ${response.status}`);
                        if (attempt === userAgents.length - 1) {
                            throw new Error(`All fetch attempts failed. Final: HTTP ${response.status}: ${response.statusText}`);
                        }
                        await new Promise(resolve => setTimeout(resolve, 1000));
                    }
                    
                } catch (error) {
                    console.log(`‚ö†Ô∏è Attempt ${attempt + 1} error: ${error.message}`);
                    if (attempt === userAgents.length - 1) {
                        console.log(`üîß All fetch attempts failed, creating manual entry...`);
                        return createManualEntry(url);
                    }
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            }
        }
        
        // Extract article data from HTML
        function extractArticleData(html, url) {
            try {
                
, 'i'), '');
                
                if (!title) {
                    title = `Article from ${siteName}`;
                }
                
                // Extract description
                const descMatches = [
                    html.match(/<meta[^>]+property="og:description"[^>]+content="([^"]+)"/i),
                    html.match(/<meta[^>]+name="description"[^>]+content="([^"]+)"/i),
                    html.match(/<meta[^>]+name="twitter:description"[^>]+content="([^"]+)"/i)
                ];
                
                const descMatch = descMatches.find(match => match);
                let description = descMatch ? descMatch[1].trim() : '';
                
                // Clean up description
                description = description.replace(/&quot;/g, '"')
                                       .replace(/&amp;/g, '&')
                                       .replace(/&lt;/g, '<')
                                       .replace(/&gt;/g, '>')
                                       .replace(/\s+/g, ' ')
                                       .trim();
                
                if (!description || description.length < 20) {
                    description = `Political article from ${siteName} requiring manual review`;
                }
                
                // Extract date with improved logic
                const dateMatches = [
                    html.match(/<meta[^>]+property="article:published_time"[^>]+content="([^"]+)"/i),
                    html.match(/<meta[^>]+name="publish-date"[^>]+content="([^"]+)"/i),
                    html.match(/<time[^>]+datetime="([^"]+)"/i),
                    html.match(/(\d{4}-\d{2}-\d{2})/g)
                ];
                
                let articleDate = new Date().toISOString().split('T')[0];
                
                for (const dateMatch of dateMatches) {
                    if (dateMatch) {
                        try {
                            let dateStr;
                            if (Array.isArray(dateMatch)) {
                                dateStr = dateMatch[0];
                            } else if (dateMatch[1]) {
                                dateStr = dateMatch[1];
                            } else {
                                continue;
                            }
                            
                            const parsedDate = new Date(dateStr);
                            if (!isNaN(parsedDate.getTime())) {
                                articleDate = parsedDate.toISOString().split('T')[0];
                                break;
                            }
                        } catch (e) {
                            continue;
                        }
                    }
                }
                
                console.log(`‚úÖ Extracted: "${title.substring(0, 60)}..."`);
                return { title, description, date: articleDate };
                
            } catch (error) {
                console.error(`‚ùå Error extracting article data: ${error.message}`);
                return createManualEntry(url);
            }
        }
        
        // Create manual entry when scraping fails
        function createManualEntry(url) {
            const domain = new URL(url).hostname.replace('www.', '');
            
            return {
                title: `Manual Article from ${domain}`,
                description: `Article submitted manually from ${domain}. Content extraction failed - requires manual review.`,
                date: new Date().toISOString().split('T')[0]
            };
        }
        }

        // Analyze with OpenAI
        async function analyzeArticle(title, description, url) {
            try {
                console.log('ü§ñ Analyzing with OpenAI...');
                
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o-mini',
                        messages: [
                            {
                                role: 'system',
                                content: 'You are a political accountability analyst. Analyze articles for Trump 2.0 Era political relevance.'
                            },
                            {
                                role: 'user',
                                content: `Analyze this article: Title: ${title}, Description: ${description}, URL: ${url}

                                Return ONLY valid JSON:
                                {
                                  "actor": "main person/organization (e.g. 'Donald Trump', 'DOJ')",
                                  "category": "Financial|Civil Liberties|Platform Manipulation|Government Oversight|Election Integrity|Corporate Ethics|Legal Proceedings",
                                  "severity": "low|medium|high",
                                  "verified": true|false
                                }`
                            }
                        ],
                        max_tokens: 300,
                        temperature: 0.3
                    })
                });

                if (!response.ok) {
                    console.warn('OpenAI API failed, using fallback');
                    return {
                        actor: 'Manual Submission',
                        category: 'Government Oversight',
                        severity: 'medium',
                        verified: isVerifiedSource(url)
                    };
                }

                const data = await response.json();
                const content = data.choices[0].message.content.trim();
                
                try {
                    const analysis = JSON.parse(content);
                    return {
                        actor: analysis.actor || 'Manual Submission',
                        category: analysis.category || 'Government Oversight',
                        severity: analysis.severity || 'medium',
                        verified: analysis.verified !== undefined ? analysis.verified : isVerifiedSource(url)
                    };
                } catch {
                    return {
                        actor: 'Manual Submission',
                        category: 'Government Oversight',
                        severity: 'medium',
                        verified: isVerifiedSource(url)
                    };
                }
                
            } catch (error) {
                console.warn(`AI analysis failed: ${error.message}`);
                return {
                    actor: 'Manual Submission',
                    category: 'Government Oversight',
                    severity: 'medium',
                    verified: isVerifiedSource(url)
                };
            }
        }

        async function processArticle() {
            try {
                // Fetch article content
                const content = await fetchArticleContent(ARTICLE_URL);
                
                // Analyze with AI
                const analysis = await analyzeArticle(content.title, content.description, ARTICLE_URL);
                
                // Create entry
                const entry = {
                    id: generateId(),
                    date: content.date,
                    actor: analysis.actor,
                    category: analysis.category,
                    title: content.title,
                    description: content.description,
                    source_url: ARTICLE_URL,
                    verified: analysis.verified,
                    severity: analysis.severity,
                    status: 'published', 
                    added_at: new Date().toISOString(),
                    manual_submission: true,
                    submitted_by: SUBMITTED_BY,
                    processed_at: new Date().toISOString()
                };
                
                // Load existing entries
                let existingEntries = [];
                try {
                    const masterData = await fs.readFile('master-tracker-log.json', 'utf8');
                    existingEntries = JSON.parse(masterData);
                } catch (error) {
                    console.log('No existing entries found, creating new tracker');
                }
                
                // Add new entry and sort
                existingEntries.unshift(entry); // Add to beginning
                existingEntries.sort((a, b) => {
                    const dateCompare = (b.date || '').localeCompare(a.date || '');
                    if (dateCompare !== 0) return dateCompare;
                    return (b.added_at || '').localeCompare(a.added_at || '');
                });
                
                // Save updated tracker
                await fs.writeFile('master-tracker-log.json', JSON.stringify(existingEntries, null, 2));
                
                console.log('‚úÖ SUCCESS: Article processed and added to tracker');
                console.log(`üìä Total entries in tracker: ${existingEntries.length}`);
                
            } catch (error) {
                console.error('‚ùå FAILED to process article:', error.message);
                process.exit(1);
            }
        }

        processArticle();
        EOF
        
        node process-single-article.js
        
    - name: Copy to public folder
      run: |
        mkdir -p public
        cp master-tracker-log.json public/master-tracker-log.json
        
    - name: Commit processed article
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action - Article Processor"
        git pull origin main
        git add master-tracker-log.json public/master-tracker-log.json
        git commit -m "Add manually submitted article: ${{ steps.extract_article.outputs.article_url }}" || echo "No changes to commit"
        git push
        
    - name: Summary
      run: |
        echo "‚úÖ Successfully processed manual article submission"
        echo "üìé URL: ${{ steps.extract_article.outputs.article_url }}"
        echo "üë§ Submitted by: ${{ steps.extract_article.outputs.submitted_by }}"
